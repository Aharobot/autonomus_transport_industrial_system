\documentclass[cs4size,a4paper]{ctexart}   

\usepackage{cite}
\usepackage{url}
%===数学符号公式===
\usepackage{amsmath}    					% AMS LaTeX宏包
\usepackage[style=1]{mdframed}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bm}                      	% 数学公式中的黑斜体
\usepackage{bbm}
\usepackage{amsfonts}
\usepackage{mathrsfs}                	% 英文花体字 体
\usepackage{bbding,manfnt}    			% 一些图标，如 \dbend
\usepackage{lettrine}                	% 首字下沉，命令\lettrine
\def\attention{\lettrine[lines=2,lraise=0,nindent=0em]{\large\textdbend\hspace{1mm}}{}}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage[toc,page]{appendix}
\usepackage{geometry}         			% 页边距调整
\geometry{top=3.0cm,bottom=2.7cm,left=2.5cm,right=2.5cm}
\usepackage[colorinlistoftodos,prependcaption,textsize=small]{todonotes}
%===公式按章编号===
\numberwithin{equation}{section}
\numberwithin{table}{section}
\numberwithin{figure}{section}
%===基本格式预置===
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}  
\fancyhead[C]{\zihao{5}  \kaishu 自动化科学导论课程报告}
\fancyfoot[C]{~\zihao{5} \thepage~}
\renewcommand{\headrulewidth}{0.75pt} 
\CTEXsetup[format={\centering\bfseries\zihao{-2}},name={第, 章}]{section}
\CTEXsetup[nameformat={\bfseries\zihao{3}}]{subsection}
\CTEXsetup[nameformat={\bfseries\zihao{4}}]{subsubsection}
%===图形支持宏包===
\usepackage{graphicx}        			% 嵌入png图像
\usepackage{subfigure}
\usepackage{float}
\graphicspath{{figure/}}
\usepackage{color,xcolor}     			% 支持彩色文本、底色、文本框等
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=blue]{hyperref}
%\usepackage{caption}
\usepackage[ruled,linesnumbered]{algorithm2e}
%\captionsetup{figurewithin=section}
%===源码和流程图===
\usepackage{listings,fontspec}         	% 粘贴源代码
\newfontfamily\consolas{Consolas}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
%===颜色===
\usepackage{color,xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\usepackage{xcolor}
\lstset{ %
%numberstyle=\tiny\monaco,
%numberstyle=\color[RGB]{0,192,192},
%backgroundcolor=\color{white},   		% choose the background color
backgroundcolor=\color[RGB]{245,245,244},
%backgroundcolor=\color[rgb]{1,1,0.76},
basicstyle=\footnotesize\consolas,       % size of fonts used for the code
identifierstyle=\footnotesize\consolas, 
columns=fullflexible,
breaklines=true,                 		% automatic line breaking only at whitespace
captionpos=b,                    		% sets the caption-position to bottom
tabsize=2,
commentstyle=\color{mygreen}\consolas,   % comment style
%commentstyle=\it\color[RGB]{0,96,96},
escapeinside={\%*}{*)},          		% if you want to add LaTeX within your code
keywordstyle=\color{blue}\consolas,      % keyword style
stringstyle=\color{mymauve}\consolas,    % string literal style
%stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},
frame=single,
rulesepcolor=\color{red!20!green!20!blue!20},
%identifierstyle=\color{red},
language=c++,
framexleftmargin=1.9mm,
xleftmargin=0.4em,
frame=none,
showstringspaces=false,
numbers=none,
}

%--------------------
\hypersetup{hidelinks}
\usepackage{booktabs}  
\usepackage{shorttoc}
\usepackage{tabu,tikz}
\usepackage{float}
\usepackage{multirow}

\tabcolsep=1ex
\tabulinesep=\tabcolsep
\newlength\tikzboxwidth
\newlength\tikzboxheight
\newcommand\tikzbox[1]{%
        \settowidth\tikzboxwidth{#1}%
        \settoheight\tikzboxheight{#1}%
        \begin{tikzpicture}
        \path[use as bounding box]
                (-0.5\tikzboxwidth,-0.5\tikzboxheight)rectangle
                (0.5\tikzboxwidth,0.5\tikzboxheight);
        \node[inner sep=\tabcolsep+0.5\arrayrulewidth,line width=0.5mm,draw=black]
                at(0,0){#1};
        \end{tikzpicture}%
        }
\makeatletter
\def\hlinew#1{%
  \noalign{\ifnum0=`}\fi\hrule \@height #1 \futurelet
   \reserved@a\@xhline}
   
\usepackage{CJK}
\usepackage{ifthen}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}%
%===使得公式随章节自动编号===
\makeatletter
\@addtoreset{equation}{section}
\makeatother
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
%-------------------------
\usepackage{pythonhighlight}
\usepackage{tikz}                    
\usepackage{tikz-3dplot}
\usetikzlibrary{shapes,arrows,positioning}
%===正文开始===
\begin{document}
%===定理类环境定义===
\newtheorem{example}{例}              	% 整体编号
\newtheorem{algorithem}{算法}	
\newtheorem{theorem}{定理}            	% 按section编号
\newtheorem{definition}{定义}
\newtheorem{axiom}{公理}
\newtheorem{property}{性质}
\newtheorem{proposition}{命题}
\newtheorem{lemma}{引理}
\newtheorem{corollary}{推论}
\newtheorem{remark}{注解}
\newtheorem{condition}{条件}
\newtheorem{conclusion}{结论}
\newtheorem{assumption}{假设}
%===重定义===
\renewcommand{\contentsname}{目录}     
\renewcommand{\abstractname}{摘要} 
\renewcommand{\refname}{参考文献}     
\renewcommand{\indexname}{索引}
\renewcommand{\figurename}{图}
\renewcommand{\tablename}{表}
\renewcommand{\appendixname}{附录}
\renewcommand{\proofname}{证明}
%\renewcommand{\algorithm}{算法} 
\renewcommand\emph[1]{\textcolor{black}{\textbf{#1}}}
%===封皮和前言===
\begin{titlepage}
\begin{center}
% Upper part of the page
\includegraphics[width=0.30\textwidth]{logo}\\[1cm]    
\textsc{\Large Beijing University of Chemical Technology}\\[1.0cm]
\textsc{\Large Computing Methods}\\[0.5cm]
% Title
\HRule \\[0.8cm]
{\huge \bfseries 自动化科学导论课程报告}\\[0.4cm]
\HRule \\[0.7cm]
% Author
\textsc{李昊}
\tableofcontents 
\vfill
% Bottom of the page
{创建日期：2020年3月25日}\\
{更新日期：\today}
\end{center}
\end{titlepage}
\pagestyle{plain}
\pagenumbering{Roman}
\thispagestyle{empty}
%===正文===
\pagestyle{fancy}
\pagenumbering{arabic}



%===第一章===
\section{自动化大类各专业之间的相互关系}
其实吧，说专业差距大，其实也没那么大。举图像识别做例子：大家都做图像识别，可能在研究生阶段区别比较大，但是
对于本科来说差别真的几乎没有。
如果一定要做区分的话
\begin{itemize}
        \item 自动化：偏向系统集成，控制算法，感知算法
        \item 测控：就我们学校，MEMS无疑
        \item 通信：各种雷达信号处理
\end{itemize}

%===第二章===
\section{学习的总结，体会和感受}
\subsection{学习的总结}
自动化学科是一门多学科交叉的高技术学科。研究内容广，几乎无所不包。但是，控制、信息、系统是其核心。自动化学科知识
体系中的核心知识是：控制与智能、对象和建模、系统和工程等三个知识领域，也是自动化学科与其他学科的最重大区别。
\subsection{学习的体会}
选自动化就对了！选自动化就对了！选自动化就对了！千万不要搞过程控制！千万不要搞过程控制！千万不要搞过程控制！
更加坚定了自己选择自动化和进行移动机器人以及机器人感知相关方向研究的意志。
\subsection{学习的感受}
与其说选择专业，我觉得更应该选择研究方向后再决定专业，因为每个专业的研究方向都有很大的重叠部分。

%===第三章===
\section{相关专业方向：同步定位与地图构建(SLAM)}
\subsection{AGV的导航（Navigation）}
导航技术是AGV技术的研究核心，没有导航功能的AGV系统是很难想象的。举个例子，如果AGV系统想要在工厂等工作场所运输货物，
它必须要在不触碰到任何障碍物的情况下运动到不同的地点。
随着信息化技术的提升，CPU算力的提升和传感器的升级，AGV的柔性路径导航吸引了越来越多的研究者进行研究，产业化应用越来越广。
柔性路径导航技术应用较多的是视觉与激光导航、惯性(IMU)导航\cite{5670227}、基于WIFI/UWB等无线信号定位\cite{4380919}的导航技术等。
机器人实现其自主导航的前提是机器人自身位姿的确定，出于对定位精度的要求以及现实环境的复杂化，
目前大多数导航系统都是由上述两种或者多种导航方式的结合组合导航技术\cite{7916260}。

\subsection{SLAM定义}
同步定位与地图构建（SLAM或Simultaneous localization and mapping）是一种概念：希望机器人从未知环境的未知地点出发，在运动过程中通过重复观测到的地图特征（比如，墙角，柱子等）定位自身位置和姿态，再根据自身位置增量式的构建地图，从而达到同时定位和地图构建的目的。

在误差和噪音条件下，定位和地图构建技术上的复杂度不支持两者同时获得连续的解。即时定位与地图构建（SLAM）是这样一个概念：把两方面的进程都捆绑在一个循环之中，以此支持双方在各自进程中都求得连续解；不同进程中相互迭代的反馈对双方的连续解有改进作用。

同步定位与地图构建（SLAM）被定义为以下问题：在建立新地图模型或者改进已知地图的同时，在该地图模型上定位机器人。实际上，这两个核心问题如果分开解决，将毫无意义；必须同时求解。
即通过控制数据$u_{1:t}$和观测数据$z_{1:t}$来求解位姿和地图的联合概率分布
\begin{align}
    p\left(x_{1: t}, m | z_{1: t}, u_{1: t-1}\right)
\end{align}

\subsection{V-SLAM的框架与分类}
视觉SLAM由前端（视觉里程计）、后端（位姿优化）、回环检测、建图4个部分组成。
\begin{itemize}
        \item  视觉里程计 (Visual Odometry)：仅有视觉输入的姿态估计\cite{1315094}
        \item 后端优化 (Optimization): 后端接受不同时刻视觉里程计测量的相机位姿，以及闭环检测的信息，对它们进行优化，得到全局一致的轨迹和地图\cite{9787121311048}
        \item 闭环检测 (Loop Closing): 指机器人在地图构建过程中, 通过视觉等传感器信息检测是否发生了轨迹闭环, 即判断自身是否进入历史同一地点\cite{9787121311048}
        \item  建图 (Mapping): 根据估计的轨迹，建立与任务要求对应的地图\cite{9787121311048}
\end{itemize}
流程如下图所示：

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{figure/framework.png}
        \caption{VSLAM流程图\cite{9787121311048}}
    \end{figure}
    
\subsection{经典V-SLAM方法}

\subsubsection{稀疏法:ORB-SLAM2}
该算法\cite{murORB2}是基于特征点的实时单目SLAM系统，在大规模的、小规模的、室内室外的环境都可以运行。它主要有以下贡献：
\begin{enumerate}[1)]
        \item 这是首个基于单目，双目和RGB-D相机的开源SLAM方案，这个方案包括，回环检测，地图重用和重定位。
        \item 结果说明，BA优化比ICP或者光度和深度误差最小方法的更加精确。
        \item 通过匹配远处和近处的双目匹配的点和单目观测，双目的结果比直接使用双目系统更加精确。
        \item 针对无法建图的情况，提出了一个轻量级的定位模式 ，能够更加有效的重用地图。
\end{enumerate}

\begin{figure}[H]
        \centering
        \includegraphics[width=0.6\textwidth]{figure/orb.png}
        \caption{ORB-SLAM主要分为三个线程进行，也就是如图所示的，分别是Tracking、LocalMapping和LoopClosing\cite{murORB2}}
    \end{figure}

\begin{enumerate}
        \item 跟踪（Tracking）\\ 这一部分主要工作是从图像中提取ORB特征，根据上一帧进行姿态估计，或者进行通过全局重定位初始化位姿，然后跟踪已经重建的局部地图，优化位姿，再根据一些规则确定新的关键帧。
        \item 建图（LocalMapping）\\ 这一部分主要完成局部地图构建。包括对关键帧的插入，验证最近生成的地图点并进行筛选，然后生成新的地图点，使用局部捆集调整（Local BA），最后再对插入的关键帧进行筛选，去除多余的关键帧。
        \begin{align}
                \{\mathbf{R}, \mathbf{t}\}=\underset{\mathbf{R}, \mathbf{t}}{\operatorname{argmin}} \sum_{i \in \mathcal{X}} \rho\left(\left\|\mathbf{x}_{(\cdot)}^{i}-\pi_{(\cdot)}\left(\mathbf{R} \mathbf{X}^{i}+\mathbf{t}\right)\right\|_{\Sigma}^{2}\right)
        \end{align}
        \item 闭环检测（LoopClosing）\\ 这一部分主要分为两个过程，分别是闭环探测和闭环校正。闭环检测先使用WOB进行探测，然后通过Sim3算法计算相似变换。闭环校正，主要是闭环融合和Essential Graph的图优化。
\end{enumerate}

\textbf{开源代码链接：}
\url{https://github.com/raulmur/ORB_SLAM2}

\subsubsection{多传感器融合:VINS-Mono}
该算法\cite{8421746}是一种鲁棒且通用的单目视觉惯性状态估计器。采用一种基于紧耦合、非线性优化的方法，通过融合预积分后的IMU测量值和特征观测值，获得高精度的视觉惯性里程计。结合紧耦合方法，回环检测模块能够以最小的计算代价实现重定位。
处理视觉和惯性测量的最简单的方法是松耦合的传感器融合\cite{8576618,8630025}，其中IMU被视为一个独立的模块，用于辅助运动的视觉结构(sfm)获得的纯视觉位姿估计。融合通常由扩展卡尔曼滤波(EKF)完成，其中IMU用于状态传播，而视觉位姿用于更新。
  
\textbf{IMU预积分（pre-integration）}

在实践中，IMU通常以比摄像机更高的速率获取数据。不同的方法被提出来处理高速率的IMU测量值。最简单的方法是在基于EKF的方法中使用IMU进行状态传播[11][13]。在图优化公式中，为了避免重复的IMU重复积分，提出了一种有效的方法，即IMU预积分(IMU pre-integration)。
通过一系列计算，得到下面的预积分估计值：
\begin{align} 
\hat{\boldsymbol{\alpha }}^{b_k}_{i+1} &= \hat{\boldsymbol{\alpha }}^{b_k}_i + \hat{\boldsymbol{\beta }}^{b_k}_i\delta t + \frac{1}{2} \mathbf {R}(\hat{\boldsymbol{\gamma }}^{b_k}_i)(\hat{\mathbf {a}}_i - \mathbf {b}_{a_i}) \delta t^2 \nonumber\\ \hat{\boldsymbol{\beta }}^{b_k}_{i+1} &= \hat{\boldsymbol{\beta }}^{b_k}_{i} + \mathbf {R}(\hat{\boldsymbol{\gamma }}^{b_k}_i)(\hat{\mathbf {a}}_i - \mathbf {b}_{a_i})\delta t\nonumber\\ \hat{\boldsymbol{\gamma }}^{b_k}_{i+1} &= \hat{\boldsymbol{\gamma }}^{b_k}_i \otimes {\left[\begin{array}{c}1\\ \frac{1}{2} (\hat{\boldsymbol{\omega }}_i- \mathbf {b}_{w_i})\delta t \end{array}\right]}
\end{align}
通过计算可以写下IMU测量模型所其对应的协方差${\mathbf {P}^{b_k}_{b_{k+1}}}$：
\begin{equation} 
{\left[\begin{array}{c}\hat{\boldsymbol{\alpha }}^{b_k}_{b_{k+1}}\\ \hat{\boldsymbol{\beta }}^{b_k}_{b_{k+1}}\\ \hat{\boldsymbol{\gamma }}^{b_k}_{b_{k+1}}\\ \mathbf {0}\\ \mathbf {0}\\ \end{array}\right]} = {\left[\begin{array}{c}\mathbf {R}^{b_k}_{w}(\mathbf {p}^{w}_{b_{k+1}} - \mathbf {p}^{w}_{b_k} + \frac{1}{2}\mathbf {g}^{w} \Delta t_k^2 - \mathbf {v}^{w}_{b_k} \Delta t_k) \\ \mathbf {R}^{b_k}_{w}(\mathbf {v}^{w}_{b_{k+1}} + \mathbf {g}^{w} \Delta t_k- \mathbf {v}^{w}_{b_k}) \\ \mathbf {q}^{w^{-1}}_{b_{k}} \otimes \mathbf {q}^{w}_{b_{k+1}}\\ {\mathbf {b}_a}_{b_{k+1}} - {\mathbf {b}_a}_{b_k}\\ {\mathbf {b}_w}_{b_{k+1}} -{\mathbf {b}_w}_{b_k}\\ \end{array}\right]}.
\end{equation}

\textbf{估计器初始化}

单目紧耦合VIO是一个高度非线性的系统。由于单目相机无法直接观测到尺度，因此，如果没有良好的初始值，很难直接将这两种测量结果融合在一起。
当IMU测量结果被大偏置破坏时，情况就变得更加复杂了。事实上，初始化通常是单目VINS最脆弱的步骤。需要一个鲁棒的初始化过程以确保系统的适用性。
通过对齐IMU预积分与纯视觉SfM结果，我们可以粗略地恢复尺度、重力、速度，甚至偏置。这足以引导非线性单目VINS估计器。

\begin{figure}[H]
        \centering
        \includegraphics[width=0.6\textwidth]{figure/vins2.png}
        \caption{总体架构图}
\end{figure}

\textbf{开源代码链接：}
\url{https://github.com/HKUST-Aerial-Robotics/VINS-Mono}

\subsubsection{blablabla}
\begin{table}[H]
        \centering
        \begin{tabular}{l|ll}
        \toprule
        比较项目   &视觉里程计 & IMU里程计\\
        \midrule[2pt]
        更新频率 & 低    & 高\\
        长时间稳定性 & 高   & 低\\
        场景依赖度 & 高  &  低\\
        重定位能力 &  高  & 低\\
        CPU功耗 &  高 & 低\\
        \bottomrule
        \end{tabular}
        \caption{视觉里程计和IMU的特性对比}
\end{table}
\begin{table}[H]
        \centering
        \begin{tabular}{l|ll}
        \toprule
        比较项目   &传统SLAM算法 & 基于深度视觉的SLAM算法\\
        \midrule[2pt]
        模型参数调整难易程度 & 数据少，调参周期短    & 数据多，调参周期长\\
        魔性物理含义 & 直观意义明确   & 缺少直观意义\\
        模型泛化能力 & 信息利用不充分，泛化能力弱  &  信息利用充分，泛化能力强\\
        适应能力 &  迁移能力弱  & 迁移能力强\\
        设计流程 &  特征设计与分类训练分离 & 同步完成特征设计和分类器训练\\
        \bottomrule
        \end{tabular}
        \caption{传统 SLAM 算法与基于深度学习的 SLAM 算法对比\cite{ZHAOYang:889}}
\end{table}

\begin{table}[H]
        \centering
        {\footnotesize\centerline{\tabcolsep=18pt\begin{tabular*}{\textwidth}{ccccc}
                \toprule
                相关文献            &方法         & 所用传感器 & 算法名称 & 发表年份  \\
                \midrule[2pt]
                \cite{9781921987243}       &稀疏法(特征点)&       单目SLAM     &       MonoSLAM       &    2014   \\
                \cite{10.1007/978-3-319-10605-2_54}     &半稠密法     &       单目SLAM     &       LSD-SLAM       & 2014\\
                \cite{murAcceptedTRO2015}&稀疏法(特征点)&       单目SLAM     &       ORB-SLAM       &   2015  \\
                \cite{6906584}            &半稠密法     &       单目SLAM     &       SVO        &      2014  \\
                \cite{murORB2}     &稀疏法(特征点)&       双目SLAM     &       ORB-SLAM2      &       2017  \\
                \cite{pire2015sptam}&稀疏法(特征点)&       双目SLAM     &       S-PTAM       &     2015\\
                \cite{6594910}      &稠密法       &       RGBD-SLAM     &       RGBD-SLAMv2       &   2014 \\
                \cite{doi:10.1002/rob.21831}      &稠密法       &       RGBD-SLAM     &       RTAB-SLAM       &   2019 \\
                \bottomrule
                \end{tabular*}}}
        \caption{传统 SLAM 算法的总结}
\end{table}


\subsection{基于深度学习的V-SLAM方法}



%===参考文献===
\addcontentsline{toc}{section}{参考文献}
\bibliographystyle{ieeetr}     %论文引用格式:缩写
\bibliography{conference_101719} %bib文件地址
\end{document}
%===结束===



